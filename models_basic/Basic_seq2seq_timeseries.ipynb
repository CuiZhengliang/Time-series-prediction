{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic time series prediction with seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Time_Seq2seq(object):\n",
    "    def __init__(self,sess,config):\n",
    "        self.sess = sess\n",
    "        self.config = config\n",
    "        self.weight = tf.get_variable(name='weight_out', shape=[self.config.lstm_hidden_size, self.config.output_dim],\n",
    "                                      dtype=tf.float32, initializer=tf.truncated_normal_initializer())\n",
    "        self.bias = tf.get_variable('bias_out', shape=[self.config.output_dim], dtype=tf.float32,\n",
    "                                    initializer=tf.constant_initializer(0.))\n",
    "        self.mode = None\n",
    "\n",
    "    def build(self):\n",
    "        self._build_init()\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        #self.summory_op=tf.summary.merge_all()\n",
    "\n",
    "        reshaped_outputs = [tf.matmul(i, self.weight) + self.bias for i in self.decoder_outputs]\n",
    "        print([i.get_shape().as_list() for i in reshaped_outputs])\n",
    "\n",
    "        with tf.variable_scope('Loss'):\n",
    "            output_loss = 0\n",
    "            for _y, _Y in zip(reshaped_outputs, self.decoder_targets):\n",
    "                output_loss += tf.reduce_mean(tf.pow(_y - _Y, 2))\n",
    "            print(output_loss)\n",
    "            self.loss = output_loss\n",
    "\n",
    "        with tf.variable_scope('Optimizer'):\n",
    "            #clip_gradients\n",
    "            #self.train_op = tf.train.AdamOptimizer(learning_rate=self.config.learning_rate).minimize(self.loss)\n",
    "            self.train_op = tf.contrib.layers.optimize_loss(loss=self.loss,\n",
    "                                                        learning_rate=self.config.learning_rate,\n",
    "                                                        global_step=self.global_step,\n",
    "                                                        optimizer='Adam',\n",
    "                                                        clip_gradients=2.5)\n",
    "\n",
    "\n",
    "    def _build_init(self):\n",
    "        self.encoder_inputs=[tf.placeholder(dtype=tf.float32,shape=(None,self.config.input_dim),name='input_x_{}'.format(t))\n",
    "                             for t in range(self.config.input_seq_length)]\n",
    "        self.decoder_targets=[tf.placeholder(dtype=tf.float32,shape=(None,self.config.output_dim),name=\"input_y_{}\".format(t))\n",
    "                              for t in range(self.config.output_seq_length)]\n",
    "        #guider training or unguided training\n",
    "        self.decoder_inputs=[tf.zeros_like(self.decoder_targets[0],dtype=tf.float32,name='GO')]+self.decoder_targets[:-1]\n",
    "        print(len(self.decoder_inputs),[i.get_shape().as_list() for i in self.decoder_inputs])\n",
    "        self.global_step=tf.train.get_or_create_global_step()\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        print(len(self.encoder_inputs),[i.get_shape().as_list() for i in self.encoder_inputs])\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            cell = self._build_encoder_cell()\n",
    "            _,self.encoder_last_state = tf.contrib.rnn.static_rnn(cell, self.encoder_inputs, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            cell=self._build_decoder_cell()\n",
    "            state = self.encoder_last_state\n",
    "            self.decoder_outputs = []\n",
    "            prev = None\n",
    "\n",
    "            for i, input in enumerate(self.decoder_inputs):\n",
    "                if self.mode!='train' and prev is not None:\n",
    "                    with tf.variable_scope(\"loop_function\", reuse=True):\n",
    "                        input = self._loop_function(prev, i)\n",
    "                if i > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    print('input',input.get_shape().as_list())\n",
    "                output, state = cell(input, state)\n",
    "                self.decoder_outputs.append(output)\n",
    "                if self.mode!='train':\n",
    "                    prev = output\n",
    "        print(len(self.decoder_outputs),[i.get_shape().as_list() for i in self.decoder_outputs])\n",
    "        #print(len(self.state),[i.get_shape().as_list() for i in self.state])\n",
    "\n",
    "\n",
    "    def _loop_function(self,prev, _):\n",
    "        return tf.matmul(prev,self.weight) + self.bias\n",
    "\n",
    "    def _build_encoder_cell(self):\n",
    "        with tf.variable_scope('encoder_cell'):\n",
    "            cells = []\n",
    "            for i in range(self.config.num_stacked_layers):\n",
    "                with tf.variable_scope('encoder_lstm_{}'.format(i)):\n",
    "                    cells.append(tf.nn.rnn_cell.LSTMCell(self.config.lstm_hidden_size))\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "        return multi_cell\n",
    "\n",
    "    def _build_decoder_cell(self):\n",
    "        with tf.variable_scope('decoder_cell'):\n",
    "            cells = []\n",
    "            for i in range(self.config.num_stacked_layers):\n",
    "                with tf.variable_scope('decoder_lstm_{}'.format(i)):\n",
    "                    cells.append(tf.nn.rnn_cell.LSTMCell(self.config.lstm_hidden_size))\n",
    "            multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "        return multi_cell\n",
    "\n",
    "    def train(self,x,y):\n",
    "        self.mode='train'\n",
    "        self.build()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        feed_dict={self.encoder_inputs[t]:x[:,t].reshape(-1,self.config.input_dim) for t in range(self.config.input_seq_length)}\n",
    "        feed_dict.update({self.decoder_targets[t]:y[:,t].reshape(-1,self.config.output_dim) for t in range(self.config.output_seq_length)})\n",
    "\n",
    "        for i in range(self.config.n_epochs):\n",
    "            _, loss = self.sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "            print(loss)\n",
    "        self.saver.save(self.sess, './result/checkpoint/seq2seq.ckpt')\n",
    "\n",
    "    def eval(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def plot(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    input_seq_length=5\n",
    "    output_seq_length=5\n",
    "    input_dim=1\n",
    "    output_dim=1\n",
    "    lstm_hidden_size=16\n",
    "    num_stacked_layers=2\n",
    "    lambda_l2_reg=0.0\n",
    "\n",
    "    learning_rate = 10e-4\n",
    "    n_epochs = 10\n",
    "    batch_size = 1\n",
    "\n",
    "\n",
    "def run_prediction_basic():\n",
    "    config = Config()\n",
    "    input_builder = Input_builder('LSTM_data.csv')\n",
    "    trainX, trainY = input_builder.create_seq2seq_basic_input(input_seq_length=config.input_seq_length,\n",
    "                                                        output_seq_length=config.output_seq_length)\n",
    "    testX, testY = input_builder.create_seq2seq_basic_input(input_seq_length=config.input_seq_length,\n",
    "                                                      output_seq_length=config.output_seq_length)\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    seq2seq = Time_Seq2seq(sess=sess,config=config)\n",
    "    seq2seq.train(trainX, trainY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
